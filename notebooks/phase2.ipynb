{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from math import log\n",
    "\n",
    "from Phase_1.src.Utils.SimplePositionalIndex import SimplePositionalIndex\n",
    "\n",
    "\n",
    "class DevelopedPositionalIndex(SimplePositionalIndex):\n",
    "    def __init__(self, configurations):\n",
    "        super().__init__(configurations)\n",
    "        self.total_number_of_documents = len(self.Documents)\n",
    "        self.document_term_tfidf_dictionary = {}\n",
    "        self.build_updated_positional_index()\n",
    "        if configurations.get_config('champions_list'):\n",
    "            self.champions_list = self.build_champions_list()\n",
    "\n",
    "    def build_updated_positional_index(self):\n",
    "        for WORD in self.positional_index_structure.keys():\n",
    "            for DOC_URL, DICTIONARY in self.positional_index_structure[WORD]['indexes'].items():\n",
    "                DICTIONARY['tf idf'] = self.get_tf_value(WORD, DOC_URL) * self.get_idf_value(WORD)\n",
    "                if DOC_URL not in self.document_term_tfidf_dictionary.keys():\n",
    "                    self.document_term_tfidf_dictionary[DOC_URL] = {WORD: DICTIONARY['tf idf']}\n",
    "                else:\n",
    "                    self.document_term_tfidf_dictionary[DOC_URL][WORD] = DICTIONARY['tf idf']\n",
    "\n",
    "    def get_tf_value(self, word, url):\n",
    "        return log(1 + self.positional_index_structure[word]['indexes'][url]['number of occurrences in document'])\n",
    "\n",
    "    def get_idf_value(self, word):\n",
    "        return log(self.total_number_of_documents / len(self.positional_index_structure[word]['indexes']))\n",
    "\n",
    "    def build_champions_list(self):\n",
    "        champions_list = {}\n",
    "        for WORD in self.positional_index_structure.keys():\n",
    "            url_tf_dictionary = {}\n",
    "            for DOC_URL, DICTIONARY in self.positional_index_structure[WORD]['indexes'].items():\n",
    "                url_tf_dictionary[DOC_URL] = self.get_tf_value(WORD, DOC_URL)\n",
    "            champions_list_size = int(\n",
    "                self.config.get_config('champions_lists_ratio') * len(self.positional_index_structure[WORD]['indexes']))\n",
    "            champions_list[WORD] = sorted(url_tf_dictionary, key=lambda item: item[1], reverse=True)[\n",
    "                                   :champions_list_size]\n",
    "        return champions_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from Phase_1.src.Utils.StopWord import Document\n",
    "from Phase_1.src.Utils.utilities import read_file, print_results\n",
    "from Phase_2.src.Utils.DevelopedPositionalIndex import DevelopedPositionalIndex\n",
    "from Phase_2.src.config import Config\n",
    "\n",
    "config = Config()\n",
    "config.set_config('documents_path', '/Volumes/Farshid_SSD/Projects/University/information retrieval/Phase_1/assets/IR_data_news_12k.json')\n",
    "docs_url, docs_title, docs_content = read_file(config.get_config('documents_path'))\n",
    "\n",
    "config.set_config('documents',\n",
    "                  [Document(content, url, title) for url, title, content in zip(docs_url, docs_title, docs_content)])\n",
    "config.set_config('champions_list', True)\n",
    "\n",
    "pos_index = DevelopedPositionalIndex(config)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "ename": "EOFError",
     "evalue": "Ran out of input",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mEOFError\u001B[0m                                  Traceback (most recent call last)",
      "Input \u001B[0;32mIn [11]\u001B[0m, in \u001B[0;36m<cell line: 15>\u001B[0;34m()\u001B[0m\n\u001B[1;32m     12\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m index\n\u001B[1;32m     14\u001B[0m \u001B[38;5;66;03m# save_index(config)\u001B[39;00m\n\u001B[0;32m---> 15\u001B[0m pos_index \u001B[38;5;241m=\u001B[39m \u001B[43mload_index\u001B[49m\u001B[43m(\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m)\u001B[49m\n",
      "Input \u001B[0;32mIn [11]\u001B[0m, in \u001B[0;36mload_index\u001B[0;34m(configurations)\u001B[0m\n\u001B[1;32m      9\u001B[0m index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     10\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mopen\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m../\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mconfigurations\u001B[38;5;241m.\u001B[39mget_config(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdump_path\u001B[39m\u001B[38;5;124m\"\u001B[39m)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/updated_pos_index.pkl\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mrb\u001B[39m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m file_to_read:\n\u001B[0;32m---> 11\u001B[0m     index \u001B[38;5;241m=\u001B[39m \u001B[43mpickle\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfile_to_read\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     12\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m index\n",
      "\u001B[0;31mEOFError\u001B[0m: Ran out of input"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "def save_index(configurations):\n",
    "    with open(f'../{configurations.get_config(\"dump_path\")}/updated_pos_index.pkl', 'w') as file_to_write:\n",
    "        pickle.dump(pos_index, file_to_write, pickle.HIGHEST_PROTOCOL)\n",
    "        print(f'saved index with name updated_pos_index.pkl')\n",
    "\n",
    "def load_index(configurations):\n",
    "    index = None\n",
    "    with open(f'../{configurations.get_config(\"dump_path\")}/updated_pos_index.pkl', 'rb') as file_to_read:\n",
    "        index = pickle.load(file_to_read)\n",
    "    return index\n",
    "\n",
    "# save_index(config)\n",
    "# pos_index = load_index(config)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from math import log\n",
    "\n",
    "from Phase_1.src.Utils.utilities import preprocess_pipeline\n",
    "\n",
    "\n",
    "class QueryHandler:\n",
    "    def __init__(self, positional_index, config):\n",
    "        self.positional_index = positional_index\n",
    "        self.config = config\n",
    "\n",
    "    def answer_query(self, query):\n",
    "        query = preprocess_pipeline(query)\n",
    "        terms = query.split()\n",
    "        if not self.config.get_config('champions_list'):\n",
    "            vector_values = self.tf_idf_calculate_normal(terms)\n",
    "        else:\n",
    "            vector_values = self.tf_idf_calculate_champions(terms)\n",
    "        scores = self.calculate_scores(vector_values)\n",
    "        results_url = dict(sorted(scores.items(), key=lambda item: item[1], reverse=True)[\n",
    "                           :self.config.get_config('documents_to_show')])\n",
    "        total_results = self.generate_total_results(results_url)\n",
    "        return total_results\n",
    "\n",
    "    def generate_total_results(self, results_url):\n",
    "        total_results = []\n",
    "        for URL, SCORE in results_url.items():\n",
    "            result = self.positional_index.url_to_information[URL]\n",
    "            result['score'] = SCORE\n",
    "            result['url'] = URL\n",
    "            total_results.append(result)\n",
    "        return total_results\n",
    "\n",
    "    def tf_idf_calculate_normal(self, terms):\n",
    "        vector_values = {}\n",
    "        tf_values = Counter(terms)\n",
    "        for term in terms:\n",
    "            positional_index_structure = self.positional_index.positional_index_structure\n",
    "            if term in positional_index_structure.keys():\n",
    "                for DOC_URL in positional_index_structure[term]['indexes'].keys():\n",
    "                    if DOC_URL not in vector_values.keys():\n",
    "                        vector_values[DOC_URL] = {}\n",
    "                    vector_values[DOC_URL][term] = \\\n",
    "                        (1 + log(tf_values[term])) * self.positional_index.get_idf_value(term)\n",
    "        return vector_values\n",
    "\n",
    "    def tf_idf_calculate_champions(self, terms):\n",
    "        vector_values = {}\n",
    "        tf_values = Counter(terms)\n",
    "        for term in terms:\n",
    "            if term in self.positional_index.positional_index_structure.keys():\n",
    "                for DOC_URL in self.positional_index.champions_list[term]:\n",
    "                    if DOC_URL not in vector_values.keys():\n",
    "                        vector_values[DOC_URL] = {}\n",
    "                    vector_values[DOC_URL][term] = \\\n",
    "                        (1 + log(tf_values[term])) * self.positional_index.get_idf_value(term)\n",
    "        return vector_values\n",
    "\n",
    "    @staticmethod\n",
    "    def cosine_similarity(v1, v2):\n",
    "        dot_product = 0\n",
    "        for term in v1.keys():\n",
    "            if term in v2.keys():\n",
    "                dot_product += v1[term] * v2[term]\n",
    "        magnitude_v1 = 0\n",
    "        for term in v1.keys():\n",
    "            magnitude_v1 += v1[term] ** 2\n",
    "        magnitude_v2 = 0\n",
    "        for term in v2.keys():\n",
    "            magnitude_v2 += v2[term] ** 2\n",
    "        return dot_product / (magnitude_v1 ** 0.5) / (magnitude_v2 ** 0.5)\n",
    "\n",
    "    def calculate_scores(self, vector_values):\n",
    "        scores = {}\n",
    "        for DOC_URL, TERM_SCORES in vector_values.items():\n",
    "            scores[DOC_URL] = self.cosine_similarity(vector_values[DOC_URL],\n",
    "                                                     self.positional_index.document_term_tfidf_dictionary[DOC_URL])\n",
    "        return scores\n",
    "\n",
    "\n",
    "query_handler = QueryHandler(pos_index, config)\n",
    "print_results(query_handler.answer_query('ایران'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print_results(query_handler.answer_query('قهرمانی تیم ملی ایران'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print_results(query_handler.answer_query('نیشابور'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print_results(query_handler.answer_query('هری کین'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}